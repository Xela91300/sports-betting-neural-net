import streamlit as st
import numpy as np
import pandas as pd
from pathlib import Path
import yaml
import glob
import joblib  # pour charger le scaler si tu l'as sauvegard√©

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Chemins fixes (plus fiables sur Streamlit Cloud & local)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
ROOT_DIR = Path(__file__).parent
MODELS_DIR = ROOT_DIR / "models"
DATA_DIR = ROOT_DIR / "data"
DATA_RAW_DIR = DATA_DIR / "raw"
DATA_PROCESSED_DIR = DATA_DIR / "processed"
CONFIG_PATH = ROOT_DIR / "config" / "config.yaml"

# Cr√©er les dossiers s'ils n'existent pas
for directory in [MODELS_DIR, DATA_RAW_DIR, DATA_PROCESSED_DIR]:
    directory.mkdir(parents=True, exist_ok=True)

# Charger la configuration
config = {}
if CONFIG_PATH.exists():
    with open(CONFIG_PATH, "r") as f:
        config = yaml.safe_load(f)
else:
    st.warning("‚ö†Ô∏è config.yaml non trouv√© ‚Üí configuration par d√©faut utilis√©e")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Configuration des sports
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
SPORT_CONFIG = {
    "Football": {
        "model_path": MODELS_DIR / "football_model.h5",
        "scaler_path": MODELS_DIR / "football_scaler.joblib",
        "features": config.get("football", {}).get("features", [
            "home_form_5", "away_form_5", "home_goals_avg", "away_goals_avg",
            "diff_classement", "odds_home", "odds_draw", "odds_away"
        ]),
        "desc": "Victoire de l'√©quipe √† domicile",
        "type": "classification",
        "data_pattern": "*football*.csv"
    },
    "Tennis": {
        "model_path": MODELS_DIR / "tennis_model.h5",
        "scaler_path": MODELS_DIR / "tennis_scaler.joblib",
        "features": config.get("tennis", {}).get("features", [
            "rank_diff", "surface_hard", "surface_clay", "surface_grass",
            "form_10_p1", "form_10_p2", "h2h_p1_wins", "fatigue_p1"
        ]),
        "desc": "Victoire du joueur 1",
        "type": "classification",
        "data_pattern": "*tennis*.csv"
    },
    "Basketball": {
        "model_path": MODELS_DIR / "basketball_model.h5",
        "scaler_path": MODELS_DIR / "basketball_scaler.joblib",
        "features": config.get("basketball", {}).get("features", [
            "points_avg_home", "reb_avg_home", "eff_rating_home",
            "back_to_back", "spread", "points_avg_away"
        ]),
        "desc": "Victoire de l'√©quipe √† domicile",
        "type": "classification",  # ou "regression" si over/under
        "data_pattern": "*basket*.csv"
    }
}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Chargement du mod√®le (Keras direct ‚Äì plus fiable)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@st.cache_resource
def load_cached_model(sport):
    path = SPORT_CONFIG[sport]["model_path"]
    if not path.exists():
        return None
    try:
        from tensorflow.keras.models import load_model
        return load_model(str(path))
    except Exception as e:
        st.error(f"Erreur chargement mod√®le {sport}: {e}")
        return None

# Chargement du scaler (si tu l'as sauvegard√© pendant l'entra√Ænement)
@st.cache_resource
def load_cached_scaler(sport):
    path = SPORT_CONFIG[sport].get("scaler_path")
    if path and path.exists():
        try:
            return joblib.load(str(path))
        except:
            return None
    return None

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Liste des datasets disponibles
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@st.cache_data(ttl=600)
def list_available_datasets(sport):
    pattern = SPORT_CONFIG[sport]["data_pattern"]
    candidates = []

    for base in [DATA_RAW_DIR, DATA_PROCESSED_DIR]:
        if base.exists():
            candidates.extend(base.rglob(pattern))
            candidates.extend(base.rglob(f"**/*{sport.lower()}*.csv"))

    # Sp√©cial TennisMyLife
    if sport == "Tennis":
        tml_dir = DATA_RAW_DIR / "tml-tennis"
        if tml_dir.exists():
            candidates.extend(tml_dir.glob("*.csv"))

    datasets = []
    for p in sorted(candidates, key=lambda x: x.stat().st_mtime, reverse=True):
        if p.is_file():
            datasets.append({
                "name": p.name,
                "path": str(p),
                "size_kb": round(p.stat().st_size / 1024, 1),
                "modified": pd.Timestamp(p.stat().st_mtime).strftime("%Y-%m-%d %H:%M"),
                "location": str(p.relative_to(ROOT_DIR))
            })
    return datasets

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Chargement d'un dataset
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@st.cache_data
def load_dataset(path_str: str):
    path = Path(path_str)
    try:
        return pd.read_csv(path)
    except Exception as e:
        st.error(f"Impossible de lire {path.name}: {e}")
        return None

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Interface
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.set_page_config(page_title="Sports Betting NN", page_icon="üéæ‚öΩüèÄ", layout="wide")

st.title("Pr√©dictions Paris Sportifs ‚Äì R√©seaux de Neurones")
st.caption("Donn√©es dans data/raw et data/processed ‚Äì Mod√®les dans models/")

# Sidebar
with st.sidebar:
    st.header("Donn√©es d√©tect√©es")
    for sport_name in SPORT_CONFIG:
        datasets = list_available_datasets(sport_name)
        icon = "‚úÖ" if datasets else "‚ö†Ô∏è"
        st.write(f"{icon} **{sport_name}**: {len(datasets)} fichier(s)")
        if datasets and st.checkbox(f"D√©tails {sport_name}", key=f"chk_{sport_name}"):
            for ds in datasets[:6]:
                st.caption(f"‚Ä¢ {ds['name']}  ({ds['size_kb']:.1f} KB)  ‚Äì {ds['modified']}")

    st.markdown("---")
    st.caption("Chemins attendus :\n‚Ä¢ data/raw/\n‚Ä¢ data/processed/\n‚Ä¢ models/")

# Colonnes principales
col_left, col_right = st.columns([1, 4])

with col_left:
    sport = st.selectbox("Sport", list(SPORT_CONFIG.keys()))

if sport:
    cfg = SPORT_CONFIG[sport]
    model = load_cached_model(sport)
    scaler = load_cached_scaler(sport)

    tab_pred, tab_data, tab_info = st.tabs(["Pr√©diction", "Donn√©es", "Infos"])

    with tab_pred:
        st.subheader(f"Pr√©diction ‚Äì {sport}")
        
        if not model:
            st.warning(f"Mod√®le {sport} introuvable ‚Üí {cfg['model_path']}")
        else:
            st.success("Mod√®le charg√©")
            st.info(f"Objectif : {cfg['desc']}")

            st.markdown("### Caract√©ristiques du match")

            user_values = {}
            cols = st.columns(3)

            for idx, feat in enumerate(cfg["features"]):
                with cols[idx % 3]:
                    label = feat.replace("_", " ").title()
                    
                    if "surface" in feat or "is_" in feat or "has_" in feat:
                        user_values[feat] = st.checkbox(label, value=False)
                    elif "odds" in feat or "cote" in feat:
                        user_values[feat] = st.number_input(label, 1.01, 50.0, 2.0, 0.1)
                    elif "rank" in feat or "diff" in feat:
                        user_values[feat] = st.number_input(label, 1, 1000, 100, 1, format="%d")
                    else:
                        user_values[feat] = st.number_input(label, -10.0, 50.0, 0.0, 0.1)

            if st.button("Pr√©dire", type="primary"):
                try:
                    # Pr√©parer le vecteur
                    X = np.array([user_values.get(f, 0.0) for f in cfg["features"]]).reshape(1, -1)
                    
                    # Appliquer scaler si disponible
                    if scaler:
                        X = scaler.transform(X)
                        st.caption("Donn√©es normalis√©es (scaler appliqu√©)")
                    
                    with st.spinner("Pr√©diction..."):
                        pred = model.predict(X, verbose=0)
                        value = float(pred[0][0])

                    if cfg["type"] == "classification":
                        proba = value
                        st.metric("Probabilit√© victoire", f"{proba:.1%}")
                        st.progress(proba)
                        if proba > 0.65:
                            st.success("Valeur potentielle d√©tect√©e")
                        elif proba > 0.5:
                            st.info("L√©g√®re faveur")
                        else:
                            st.warning("Faible probabilit√©")
                    else:
                        st.metric("Valeur pr√©dite", f"{value:.2f}")

                except Exception as e:
                    st.error(f"Erreur pr√©diction : {e}")

    with tab_data:
        st.subheader(f"Donn√©es ‚Äì {sport}")
        datasets = list_available_datasets(sport)

        if datasets:
            df_files = pd.DataFrame(datasets)
            st.dataframe(df_files[["name", "size_kb", "modified", "location"]])

            selected = st.selectbox("Fichier √† explorer", [d["name"] for d in datasets])
            if selected:
                file = next(d for d in datasets if d["name"] == selected)
                df = load_dataset(file["path"])
                if df is not None:
                    st.markdown(f"**Aper√ßu : {selected}** ({len(df)} lignes)")
                    st.dataframe(df.head(15))
                    
                    with st.expander("Statistiques descriptives"):
                        st.dataframe(df.describe())
                    
                    with st.expander("Colonnes"):
                        st.write(list(df.columns))
        else:
            st.info("Aucune donn√©e trouv√©e. Placez vos CSV dans data/raw/ ou data/processed/")

    with tab_info:
        st.subheader("Informations techniques")
        st.markdown("**Features attendues :**")
        for f in cfg["features"]:
            st.markdown(f"- `{f}`")
        
        st.markdown("**Mod√®le :**")
        st.code(f"{cfg['model_path'].name if cfg['model_path'].exists() else 'Non trouv√©'}")
        
        st.markdown("**Scaler :**")
        st.code("Pr√©sent" if scaler else "Absent (pr√©dictions non normalis√©es)")

st.markdown("---")
st.caption("Projet √©ducatif ‚Äì Pas de garantie de gain ‚Äì Jouez responsablement")
