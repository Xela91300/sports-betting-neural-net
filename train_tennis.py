"""
Script d'entraÃ®nement â€“ ModÃ¨le Tennis
DonnÃ©es : format TML (tourney_id, winner_rank, loser_rank, surface, stats...)
Usage   : python train_tennis.py
Sortie  : models/tennis_model.h5 + models/tennis_scaler.joblib
"""

import os
import glob
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score
import joblib

# â”€â”€ TensorFlow / Keras â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
import tensorflow as tf
from tensorflow import keras

print(f"TensorFlow {tf.__version__}")

# â”€â”€ Chemins â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT_DIR   = Path(__file__).parent
DATA_DIR   = ROOT_DIR / "src" / "data" / "raw" / "tml-tennis"
MODELS_DIR = ROOT_DIR / "models"
MODELS_DIR.mkdir(exist_ok=True)

# â”€â”€ 1. Chargement de tous les CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
csv_files = sorted(DATA_DIR.glob("*.csv"))
if not csv_files:
    raise FileNotFoundError(f"Aucun CSV trouvÃ© dans {DATA_DIR}")

print(f"\nğŸ“‚ {len(csv_files)} fichier(s) trouvÃ©(s) :")
for f in csv_files:
    print(f"   â€¢ {f.name}")

df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)
print(f"\nâœ… Dataset total : {len(df)} matchs, {df.shape[1]} colonnes")

# â”€â”€ 2. Feature Engineering â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Surface â†’ encodage one-hot
df["surface_hard"]  = (df["surface"] == "Hard").astype(int)
df["surface_clay"]  = (df["surface"] == "Clay").astype(int)
df["surface_grass"] = (df["surface"] == "Grass").astype(int)

# DiffÃ©rence de classement (winner - loser, du point de vue joueur A)
# On va crÃ©er 2 lignes par match : une oÃ¹ A=winner, une oÃ¹ A=loser â†’ Ã©quilibre
def build_balanced_dataset(df):
    records = []

    for _, row in df.iterrows():
        w_rank = row.get("winner_rank", np.nan)
        l_rank = row.get("loser_rank", np.nan)
        w_pts  = row.get("winner_rank_points", np.nan)
        l_pts  = row.get("loser_rank_points", np.nan)
        w_age  = row.get("winner_age", np.nan)
        l_age  = row.get("loser_age", np.nan)
        best_of = row.get("best_of", 3)

        surf_h = int(row.get("surface_hard", 0))
        surf_c = int(row.get("surface_clay", 0))
        surf_g = int(row.get("surface_grass", 0))

        # Stats de service gagnant (si disponibles)
        w_ace   = row.get("w_ace", np.nan)
        w_df    = row.get("w_df", np.nan)
        w_svpt  = row.get("w_svpt", np.nan)
        w_1stIn = row.get("w_1stIn", np.nan)
        w_1stWon= row.get("w_1stWon", np.nan)
        w_bpSaved = row.get("w_bpSaved", np.nan)
        w_bpFaced = row.get("w_bpFaced", np.nan)

        l_ace   = row.get("l_ace", np.nan)
        l_df    = row.get("l_df", np.nan)
        l_svpt  = row.get("l_svpt", np.nan)
        l_1stIn = row.get("l_1stIn", np.nan)
        l_1stWon= row.get("l_1stWon", np.nan)
        l_bpSaved = row.get("l_bpSaved", np.nan)
        l_bpFaced = row.get("l_bpFaced", np.nan)

        # % 1Ã¨re balle
        w_1st_pct = (w_1stWon / w_1stIn) if (w_1stIn and w_1stIn > 0) else np.nan
        l_1st_pct = (l_1stWon / l_1stIn) if (l_1stIn and l_1stIn > 0) else np.nan

        # % bp sauvÃ©es
        w_bp_pct = (w_bpSaved / w_bpFaced) if (w_bpFaced and w_bpFaced > 0) else np.nan
        l_bp_pct = (l_bpSaved / l_bpFaced) if (l_bpFaced and l_bpFaced > 0) else np.nan

        base = {
            "surface_hard": surf_h,
            "surface_clay": surf_c,
            "surface_grass": surf_g,
            "best_of": best_of,
        }

        # Observation A = winner (label 1)
        records.append({
            **base,
            "rank_p1": w_rank,
            "rank_p2": l_rank,
            "rank_diff": (w_rank - l_rank) if (pd.notna(w_rank) and pd.notna(l_rank)) else np.nan,
            "pts_diff": (w_pts - l_pts) if (pd.notna(w_pts) and pd.notna(l_pts)) else np.nan,
            "age_diff": (w_age - l_age) if (pd.notna(w_age) and pd.notna(l_age)) else np.nan,
            "ace_diff": (w_ace - l_ace) if (pd.notna(w_ace) and pd.notna(l_ace)) else np.nan,
            "df_diff":  (w_df  - l_df)  if (pd.notna(w_df)  and pd.notna(l_df))  else np.nan,
            "1st_pct_diff": (w_1st_pct - l_1st_pct) if (pd.notna(w_1st_pct) and pd.notna(l_1st_pct)) else np.nan,
            "bp_pct_diff":  (w_bp_pct  - l_bp_pct)  if (pd.notna(w_bp_pct)  and pd.notna(l_bp_pct))  else np.nan,
            "label": 1
        })

        # Observation B = loser (label 0) â†’ symÃ©trie
        records.append({
            **base,
            "rank_p1": l_rank,
            "rank_p2": w_rank,
            "rank_diff": (l_rank - w_rank) if (pd.notna(l_rank) and pd.notna(w_rank)) else np.nan,
            "pts_diff": (l_pts - w_pts) if (pd.notna(l_pts) and pd.notna(w_pts)) else np.nan,
            "age_diff": (l_age - w_age) if (pd.notna(l_age) and pd.notna(w_age)) else np.nan,
            "ace_diff": (l_ace - w_ace) if (pd.notna(l_ace) and pd.notna(w_ace)) else np.nan,
            "df_diff":  (l_df  - w_df)  if (pd.notna(l_df)  and pd.notna(w_df))  else np.nan,
            "1st_pct_diff": (l_1st_pct - w_1st_pct) if (pd.notna(l_1st_pct) and pd.notna(w_1st_pct)) else np.nan,
            "bp_pct_diff":  (l_bp_pct  - w_bp_pct)  if (pd.notna(l_bp_pct)  and pd.notna(w_bp_pct))  else np.nan,
            "label": 0
        })

    return pd.DataFrame(records)

print("\nâš™ï¸  Construction du dataset Ã©quilibrÃ©...")
data = build_balanced_dataset(df)
print(f"   Observations : {len(data)} (dont {data['label'].sum()} victoires)")

# â”€â”€ 3. Nettoyage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FEATURES = [
    "rank_diff", "pts_diff", "age_diff",
    "surface_hard", "surface_clay", "surface_grass",
    "best_of", "ace_diff", "df_diff", "1st_pct_diff", "bp_pct_diff"
]

# Remplir les NaN par la mÃ©diane de chaque feature
for feat in FEATURES:
    median = data[feat].median()
    data[feat] = data[feat].fillna(median)

X = data[FEATURES].values
y = data["label"].values

print(f"\nğŸ“Š Features utilisÃ©es ({len(FEATURES)}) : {FEATURES}")

# â”€â”€ 4. Split train / test â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print(f"\nğŸ”€ Split : {len(X_train)} train / {len(X_test)} test")

# â”€â”€ 5. Normalisation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test  = scaler.transform(X_test)

scaler_path = MODELS_DIR / "tennis_scaler.joblib"
joblib.dump(scaler, scaler_path)
print(f"ğŸ’¾ Scaler sauvegardÃ© â†’ {scaler_path}")

# â”€â”€ 6. ModÃ¨le â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model = keras.Sequential([
    keras.layers.Input(shape=(len(FEATURES),)),
    keras.layers.Dense(128, activation="relu"),
    keras.layers.BatchNormalization(),
    keras.layers.Dropout(0.3),
    keras.layers.Dense(64, activation="relu"),
    keras.layers.BatchNormalization(),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(32, activation="relu"),
    keras.layers.Dense(1, activation="sigmoid")
])

model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss="binary_crossentropy",
    metrics=["accuracy", keras.metrics.AUC(name="auc")]
)

model.summary()

# â”€â”€ 7. EntraÃ®nement â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
callbacks = [
    keras.callbacks.EarlyStopping(
        monitor="val_auc", patience=15, restore_best_weights=True, mode="max"
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor="val_loss", factor=0.5, patience=7, min_lr=1e-5
    )
]

print("\nğŸš€ EntraÃ®nement...")
history = model.fit(
    X_train, y_train,
    validation_split=0.15,
    epochs=150,
    batch_size=64,
    callbacks=callbacks,
    verbose=1
)

# â”€â”€ 8. Ã‰valuation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ“ˆ Ã‰valuation sur le jeu de test :")
loss, acc, auc = model.evaluate(X_test, y_test, verbose=0)
print(f"   Loss     : {loss:.4f}")
print(f"   Accuracy : {acc:.4f} ({acc*100:.1f}%)")
print(f"   AUC      : {auc:.4f}")

y_pred = (model.predict(X_test, verbose=0) > 0.5).astype(int).flatten()
print("\nğŸ“‹ Rapport de classification :")
print(classification_report(y_test, y_pred, target_names=["DÃ©faite", "Victoire"]))

# â”€â”€ 9. Sauvegarde du modÃ¨le â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model_path = MODELS_DIR / "tennis_model.h5"
model.save(str(model_path))
print(f"\nâœ… ModÃ¨le sauvegardÃ© â†’ {model_path}")

# â”€â”€ 10. RÃ©sumÃ© des features pour config.yaml â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ“ Copiez ces features dans config/config.yaml :")
print("tennis:")
print("  features:")
for f in FEATURES:
    print(f"    - {f}")
